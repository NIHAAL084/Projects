# ğŸ“˜ README.md

&#x20;&#x20;

**FAQ_Chatbot** is a locally deployable, Retrieval-Augmented Generation (RAG) augmented chatbot. It leverages **n8n** orchestration, a **Chroma** vector store, and **Ollama** embeddings/LLMs to deliver accurate, ethically framed answers enriched by text, image, and table context. A builtâ€‘in Gradio UI and analytics dashboard provide a seamless user experience and real-time insights.

![Workflow Diagram](workflow.png)
---

## ğŸš€ Key Features

- **RAG-Powered Retrieval**: Semantic search over locally hosted documents (PDF, TXT, MD)
- **Multi-Modal Inputs**: Text, Image (captioning/OCR), and Table (statistical summaries)
- **Local Hosting And Multi LLM Support**: Switch easily between Mistral, Llama3, Gemma, Falcon, Qwen via Ollama
- **Workflow Orchestration**: Visual pipelines in n8n with error handling & logging
- **Session Management**: MongoDB for conversation memory & response caching
- **Analytics Dashboard**: Query frequency, answer lengths, multimodal usage, fallback ratio

---

## ğŸ—ï¸ Tech Stack

| Component              | Technology                    |
| ---------------------- | ----------------------------- |
| Embeddings & LLMs      | Ollama (`mxbai-embed-large`)  |
| Vector Store           | Chroma DB (local, persistent) |
| Workflow Orchestration | n8n                           |
| Frontend UI            | Gradio                        |
| API Framework          | FastAPI                       |
| Database               | MongoDB + Mongo Express       |
| Deployment             | Docker & Docker Compose       |

---

## ğŸ“‚ Repository Structure

```
rag-chatbot-project/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ rag-chatbot-workflow.json    # n8n workflow definition
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ engineer-data.py                 # document preprocessing & splitting
â”‚   â”œâ”€â”€ ingest_to_db.py                  # loader â†’ chunk â†’ embed â†’ Chroma
â”‚   â”œâ”€â”€ rag_query_server.py              # FastAPI wrapper for vector search
â”‚   â””â”€â”€ ui_server.py                     # Gradio UI + caching + analytics
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw-data/                        # original dataset CSVs
â”‚   â”œâ”€â”€ sample-documents/                # generated PDF, TXT, MD files
â”‚   â””â”€â”€ chroma/                          # persistent vector DB files
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md                        # this file
â”‚   â””â”€â”€ technical-approach.md            # design & rationale
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ sample-queries.json              # test queries
â”‚   â””â”€â”€ images.jpg                       # test image
â”‚   â””â”€â”€ International-Space-Station.csv  # test csv
â”œâ”€â”€ compose.yaml                         # Docker Compose configuration
â”œâ”€â”€ .env                                 # environment variables
â””â”€â”€ pyproject.toml                       # Python project config
```

---

## âš™ï¸ Getting Started

### Prerequisites

- **Docker** & **Docker Compose**
- **Python 3.10+**
- [**uv**](https://github.com/astral-sh/uv) package manager

### Installation

```bash
# Clone repository
git clone https://github.com/your-org/rag-chatbot-project.git
cd rag-chatbot-project

# Initialize Virtual Environment & install Python deps
uv venv
uv sync

# Launch Docker services
docker compose up -d
```

### Run Services

1. **RAG Query Server** (port 8000)

   ```bash
   uv run uvicorn scripts/rag_query_server:app --reload --port 8000
   ```

2. **UI & Analytics** (port 7860)

   ```bash
   uv run scripts/ui_server.py
   ```

3. **Access Interfaces**

   - **n8n Editor** â†’ `http://localhost:5678`
   - **Gradio Chat UI** â†’ `http://localhost:7860`
   - **Mongo Express** â†’ `http://localhost:8081`

---

## ğŸ“– Usage Example

```bash
# Submit a question via API
curl -X POST http://localhost:5678/webhook-test/ask-faq \
  -H "Content-Type: application/json" \
  -d '{"query": "What is Retrieval-Augmented Generation?"}'
```

Visit the Gradio UI to interact with images, tables, and view analytics in real time.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/YourFeature`)
3. Commit your changes (`git commit -m 'Add feature'`)
4. Push to branch (`git push origin feature/YourFeature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

---
